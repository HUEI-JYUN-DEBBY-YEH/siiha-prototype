
import gradio as gr
from inference_siiha import load_model, generate_response

model, tokenizer = load_model()

def chat_with_siiha(user_input):
    return generate_response(user_input, model, tokenizer)

with gr.Blocks() as demo:
    gr.Markdown("""
    # ğŸ¤– SIIHA Demo Assistant
    ç”± Zephyr-7B LoRA å¾®èª¿è€Œæˆçš„æŒ‡ä»¤å‹åŠ©ç†ï¼Œå¯å›æ‡‰å…·å°ç£èªå¢ƒçš„ä»»å‹™æŒ‡ç¤º
    """)
    with gr.Row():
        input_text = gr.Textbox(label="user_input", lines=5, placeholder="è«‹è¼¸å…¥ä¸€æ®µè·å ´å°è©±ã€æƒ…ç·’åæ‡‰æˆ–è«‹æ±‚")
        output_text = gr.Textbox(label="output", lines=5)
    with gr.Row():
        clear_btn = gr.Button("æ¸…é™¤")
        submit_btn = gr.Button("æäº¤")

    submit_btn.click(fn=chat_with_siiha, inputs=input_text, outputs=output_text)
    clear_btn.click(fn=lambda: ("", ""), inputs=[], outputs=[input_text, output_text])

demo.launch()
