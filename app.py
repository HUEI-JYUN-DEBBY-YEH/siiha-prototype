import gradio as gr
from inference_siiha import load_model, generate_response

# è¼‰å…¥æ¨¡å‹
model, tokenizer = load_model()

# å®šç¾© Gradio ä»‹é¢
def chat_with_siiha(user_input):
    return generate_response(user_input, model, tokenizer)

iface = gr.Interface(
    fn=chat_with_siiha,
    inputs=gr.Textbox(lines=4, placeholder="è«‹è¼¸å…¥ä¸€æ®µè©±ï¼Œä¾‹å¦‚ï¼šå¯ä»¥å¹«æˆ‘æ’°å¯«ä¸€å°äººè³‡ä¿¡ä»¶å—ï¼Ÿ"),
    outputs="text",
    title="ğŸ¤– SIIHA Demo Assistant",
    description="ç”± Zephyr-7B LoRA å¾®èª¿è€Œæˆçš„æŒ‡ä»¤å‹åŠ©ç†ï¼Œå¯å›æ‡‰å…·å°ç£èªå¢ƒçš„ä»»å‹™æŒ‡ç¤º",
)

if __name__ == "__main__":
    iface.launch()
